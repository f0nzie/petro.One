---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


```{r setup, include=F, error=T, message=F, warning=F}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      error = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align = 'center')
```


## load paper object from previous OnePetro scan

```{r rows.print=25}
library(petro.One)
library(RWeka)
library(tm)
library(tidyverse)


# load previous findings
load(file = paste0("rese_rese_mach_mach", ".rda"))
papers <- paper_search_obj$papers
papers
```

## Create the corpus from the papers dataframe

```{r}
data("stopwords")  # remove custom stopwords

vdocs <- VCorpus(VectorSource(papers$book_title))

vdocs <- tm_map(vdocs, content_transformer(tolower)) # convert to lowercase
vdocs <- tm_map(vdocs, removePunctuation)      # remove all punctuation
vdocs <- tm_map(vdocs, stripWhitespace)        # remove whitespaces
vdocs <- tm_map(vdocs, removeWords, stopwords("english")) # remove built-in stopwords
vdocs <- tm_map(vdocs, removeWords, custom_stopwords)

vdocs <- tm_map(vdocs, stemDocument, language = "english")  

```



```{r rows.print=25}
options(mc.cores=1)

threegramTokenizer <- function(x) {
    NGramTokenizer(x, Weka_control(min=3, max=3))
}

tdm3 <- TermDocumentMatrix(vdocs,
                           control=list(tokenize=threegramTokenizer))

tdm3.matrix <- as.matrix(tdm3)
tdm3.rs <- sort(rowSums(tdm3.matrix), decreasing=TRUE)
tdm3.df <- data.frame(word = names(tdm3.rs), freq = tdm3.rs, stringsAsFactors = FALSE)
row.names(tdm3.df) <- NULL
head(tdm3.df, 35)

```


```{r}
custom_stopwords_3 <- c("artifici neural network",
                        "artifici intellig techniqu",
                        "oil gas industri",
                        "applic artifici intellig",
                        "ensembl kalman filter",
                        "genet algorithm optim",
                        "machin learn",
                        "histori match",
                        "data mine"
                        )
```

```{r rows.print=25}
vdocs <- tm_map(vdocs, removeWords, custom_stopwords_3)

tdm3 <- TermDocumentMatrix(vdocs,
                           control=list(tokenize=threegramTokenizer))

tdm3.matrix <- as.matrix(tdm3)
tdm3.rs <- sort(rowSums(tdm3.matrix), decreasing=TRUE)
tdm3.df <- data.frame(word = names(tdm3.rs), freq = tdm3.rs, stringsAsFactors = FALSE)
row.names(tdm3.df) <- NULL
head(tdm3.df, 25)
```



```{r fig.asp=1}
p2 <- ggplot(subset(tdm3.df, freq > 3), aes(x=reorder(word, freq), y=freq)) + 
    geom_bar(stat = "identity") + 
    xlab("Terms") + ylab("Count") + 
    coord_flip()

p2
```


```{r}
papers %>% 
    filter(grepl(pattern = "enhanced oil recovery", x = book_title, ignore.case = TRUE))
```

```{r}
papers %>% 
    filter(grepl(pattern = "well placement optim", x = book_title, ignore.case = TRUE))
```
